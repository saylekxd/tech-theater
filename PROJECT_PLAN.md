# Tech Theater - Plan Projektu

## ğŸ“‹ Opis Projektu
Aplikacja webowa w Next.js z **gÅ‚osowÄ… interakcjÄ…** LLM i animowanÄ… postaciÄ….

**GÅ‚Ã³wne funkcjonalnoÅ›ci:**
- Rozmowa GÅOSOWA z LLM wcielajÄ…cym siÄ™ w postaÄ‡ z wystÄ™pu
- UÅ¼ytkownik mÃ³wi â†’ LLM przetwarza â†’ PostaÄ‡ odpowiada gÅ‚osem
- Synchronizacja animacji wideo z stanami LLM (czekanie/sÅ‚uchanie/odpowiadanie)
- BRAK interfejsu tekstowego - tylko interakcja gÅ‚osowa

**Stack Audio:**
- **Speech-to-Text:** Web Speech API lub OpenAI Whisper
- **LLM:** OpenAI GPT / Anthropic Claude / inne
- **Text-to-Speech:** ElevenLabs (rekomendowane) lub OpenAI TTS

---

## ğŸ”„ Flow Aplikacji (Overview)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. WAITING STATE                                           â”‚
â”‚  â”œâ”€ Video: waiting.mp4 (loop)                              â”‚
â”‚  â””â”€ UI: Button "NaciÅ›nij aby mÃ³wiÄ‡"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  [User clicks button]
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. LISTENING STATE                                         â”‚
â”‚  â”œâ”€ Video: listening.mp4 (loop)                            â”‚
â”‚  â”œâ”€ Audio: Nagrywanie mikrofonu (MediaRecorder)            â”‚
â”‚  â”œâ”€ UI: "SÅ‚ucham..." + audio visualizer                    â”‚
â”‚  â””â”€ Auto-stop: silence detection lub manual stop           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  [Recording stopped]
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PROCESSING STATE (substany)                            â”‚
â”‚                                                              â”‚
â”‚  3a. TRANSCRIBING                                           â”‚
â”‚      â”œâ”€ Video: listening.mp4 (kontynuacja)                 â”‚
â”‚      â”œâ”€ API: OpenAI Whisper (Speech-to-Text)               â”‚
â”‚      â”œâ”€ WysyÅ‚anie audio do /api/speech-to-text             â”‚
â”‚      â””â”€ UI: "RozpoznajÄ™ mowÄ™..."                           â”‚
â”‚                           â†“                                  â”‚
â”‚  3b. THINKING                                               â”‚
â”‚      â”œâ”€ Video: listening.mp4 (kontynuacja)                 â”‚
â”‚      â”œâ”€ API: LLM (GPT/Claude) generates response           â”‚
â”‚      â””â”€ UI: "MyÅ›lÄ™..."                                      â”‚
â”‚                           â†“                                  â”‚
â”‚  3c. SYNTHESIZING                                           â”‚
â”‚      â”œâ”€ Video: listening.mp4 (kontynuacja)                 â”‚
â”‚      â”œâ”€ API: ElevenLabs TTS                                â”‚
â”‚      â””â”€ UI: "PrzygotowujÄ™ odpowiedÅº..."                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  [Audio ready to play]
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. RESPONDING STATE                                        â”‚
â”‚  â”œâ”€ Video: responding.mp4 (loop - sync z audio)            â”‚
â”‚  â”œâ”€ Audio: Odtwarzanie TTS z ElevenLabs                    â”‚
â”‚  â”œâ”€ UI: Opcjonalna transkrypcja co mÃ³wi postaÄ‡             â”‚
â”‚  â””â”€ Button: "Przerwij" (stop audio)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  [Audio playback ended]
                           â†“
                    [Return to State 1]
```

---

## ğŸ—ï¸ Faza 1: Setup Projektu

### 1.1 Inicjalizacja
- [X] Utworzenie projektu Next.js z TypeScript
- [X] Konfiguracja ESLint i Prettier
- [X] Setup Git i .gitignore
- [X] Instalacja podstawowych dependencji
  - [X] Tailwind CSS (styling)
  - [X] Shadcn/ui (komponenty UI - przyciski, ikony)
  - [X] Zustand lub Context API (state management)
  - [X] ElevenLabs SDK (TTS)
  - [X] OpenAI SDK (opcjonalnie dla Whisper STT)

### 1.2 Struktura FolderÃ³w
- [X] Utworzenie struktury:
  ```
  /app
    /api
      /speech-to-text
      /llm-chat
      /text-to-speech
    /components
      /VideoPlayer
      /VoiceControls
      /AudioVisualizer
    /lib
      /elevenlabs
      /llm
      /audio
    /types
  /public
    /videos
      - waiting.mp4
      - listening.mp4
      - responding.mp4
  ```

---

## ğŸ¨ Faza 2: UI i Podstawowe Komponenty

### 2.1 Layout GÅ‚Ã³wny
- [X] Stworzenie layoutu aplikacji
- [X] Responsywny design (mobile + desktop)
- [X] Sekcja na wideo (animowana postaÄ‡) - gÅ‚Ã³wny element
- [X] Minimalistyczny interfejs - focus na postaci
- [X] Przyciski kontrolne na dole/gÃ³rze

### 2.2 Video Player
- [X] Komponent VideoPlayer z trzema stanami
  - [X] Stan: `waiting` - wyÅ›wietla waiting.mp4 (loop)
  - [X] Stan: `listening` - wyÅ›wietla listening.mp4 (loop)
  - [X] Stan: `responding` - wyÅ›wietla responding.mp4 (loop + synchronizacja z audio)
- [X] PÅ‚ynne przejÅ›cia miÄ™dzy filmami
- [X] Autoplay (bÄ™dzie potrzebny user gesture)
- [X] Preloading wszystkich trzech filmÃ³w
- [X] Fullscreen lub large viewport

### 2.3 Voice Controls UI
- [X] DuÅ¼y button "NaciÅ›nij aby mÃ³wiÄ‡" / "Push to Talk"
- [X] Lub: "Tap to Start" z auto-detection mowy
- [X] Wizualna indykacja stanu:
  - [X] PulsujÄ…cy button podczas sÅ‚uchania
  - [X] Animation podczas przetwarzania
  - [X] Disabled podczas odpowiedzi
- [X] Button "Stop/Przerwij" (aby przerwaÄ‡ odpowiedÅº)

### 2.4 Audio Visualizer (opcjonalnie)
- [X] Wizualizacja fal dÅºwiÄ™kowych podczas:
  - [X] Gdy uÅ¼ytkownik mÃ³wi
  - [X] Gdy postaÄ‡ odpowiada
- [X] Canvas API lub biblioteka (wavesurfer.js)

---

## ğŸ¤ Faza 3: Speech-to-Text (STT) - OBOWIÄ„ZKOWE

### 3.1 WybÃ³r Metody STT
**âœ… WYBRANA: OpenAI Whisper (lepsza jakoÅ›Ä‡)**
- [X] Nagrywanie audio w przeglÄ…darce (MediaRecorder)
- [X] WysyÅ‚anie audio do API endpoint
- [X] Endpoint `/api/speech-to-text` z Whisper API
- [X] ObsÅ‚uga rÃ³Å¼nych formatÃ³w (webm, mp3, wav)
- [X] Model: `whisper-1` (jedyny dostÄ™pny przez API)
- âœ… Zalety: Najlepsza jakoÅ›Ä‡, wielojÄ™zyczne, dziaÅ‚a w kaÅ¼dej przeglÄ…darce
- âœ… Bardzo dokÅ‚adne rozpoznawanie polskiego
- âš ï¸ Wady: PÅ‚atne (~$0.006/minuta), wymaga backendu, minimalne opÃ³Åºnienie


### 3.2 Implementacja Nagrywania (dla Whisper)
- [X] Hook `useVoiceRecording` lub komponent
- [X] MediaRecorder API setup:
  ```typescript
  const mediaRecorder = new MediaRecorder(stream, {
    mimeType: 'audio/webm;codecs=opus' // Lub audio/mp4
  });
  ```
- [X] Start/Stop recording
- [X] Zbieranie audio chunks do Blob
- [X] Konwersja do formatu akceptowanego przez Whisper (webm/mp3/wav)
- [X] Error handling:
  - [X] Brak mikrofonu
  - [X] Permission denied
  - [X] NieobsÅ‚ugiwany format
  - [X] PrzeglÄ…darka nie obsÅ‚uguje MediaRecorder

### 3.3 API Endpoint `/api/speech-to-text`
- [X] Utworzenie Next.js route handler
- [X] Import OpenAI SDK:
  ```typescript
  import OpenAI from 'openai';
  
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  });
  ```
- [X] Przyjmowanie audio jako FormData
- [X] WywoÅ‚anie Whisper API:
  ```typescript
  const transcription = await openai.audio.transcriptions.create({
    file: audioFile,
    model: "whisper-1",
    language: "pl", // Opcjonalne - wymusza polski
    response_format: "json",
    temperature: 0.0 // Dla wiÄ™kszej accuracy
  });
  ```
- [X] Return transkrypcji jako JSON
- [X] Error handling i timeout (max 30s)
- [X] Rate limiting (opcjonalnie)

### 3.4 Auto-Stop Detection (waÅ¼ne dla UX)
- [X] Implementacja silence detection:
  - [X] Analiza poziomu audio w real-time
  - [X] JeÅ›li cisza przez 1.5-2s â†’ auto-stop
  - [X] Prevents user having to manually click "stop"
- [X] UÅ¼yj Web Audio API:
  ```typescript
  const analyser = audioContext.createAnalyser();
  // Monitoruj volume level
  // JeÅ›li volume < threshold przez 1.5s â†’ stop
  ```
- [X] Lub: prostsze rozwiÄ…zanie z timeoutem

### 3.5 UI Feedback
- [X] Timer nagrywania (pokazuje ile sekund)
- [X] Wizualizacja poziomu gÅ‚oÅ›noÅ›ci (audio meter)
- [X] Stany:
  - [X] "SÅ‚ucham..." (nagrywanie)
  - [X] "RozpoznajÄ™ mowÄ™..." (Whisper processing ~0.5-2s)
  - [X] WyÅ›wietlenie transkrypcji (co rozpoznaÅ‚)
- [X] Button "Przerwij nagrywanie"
- [X] Max czas nagrywania (np. 60s - Whisper limit 25MB file size)

### 3.6 Whisper Best Practices
- [X] Format audio: webm/opus (najmniejszy rozmiar)
- [X] Fallback formats: mp3, mp4, wav
- [X] Parametr `language: "pl"` - przyspiesza processing
- [X] `temperature: 0.0` - maksymalna dokÅ‚adnoÅ›Ä‡
- [X] ObsÅ‚uga bÅ‚Ä™dÃ³w:
  - [X] File too large (max 25MB)
  - [X] Invalid format
  - [X] API timeout (retry logic)
- [X] Cache API key validation

---

## ğŸ¤– Faza 4: Integracja LLM (do generowania odpowiedzi)

### 4.1 API Route
- [X] Utworzenie `/api/llm-chat` endpoint
- [X] WybÃ³r providera LLM (do tekstowych odpowiedzi):
  - [X] **OpenAI GPT-5.2** (NAJNOWSZY - 11.12.2025)
  - [X] **OpenAI GPT-4o / GPT-3.5** (alternatywy)
  - [X] **Anthropic Claude** (konfiguracja dostÄ™pna)
  - [X] **Groq** (konfiguracja dostÄ™pna)
- [X] ZarzÄ…dzanie kluczem API (environment variables)
- [X] Format requestu: `{ messages: [], characterId: string }`

### 4.2 System PromptÃ³w dla Postaci
- [X] Plik konfiguracyjny `/lib/characters.ts`
- [X] Struktura:
  ```typescript
  interface Character {
    id: string;
    name: string;
    systemPrompt: string;  // Tu dodasz instrukcje postaci
    voiceId: string;       // ID gÅ‚osu z ElevenLabs
    temperature: number;   // KreatywnoÅ›Ä‡ odpowiedzi
    maxTokens: number;     // DÅ‚ugoÅ›Ä‡ odpowiedzi
  }
  ```
- [X] Placeholder systemprompt do pÃ³Åºniejszego dodania
- [X] MoÅ¼liwoÅ›Ä‡ wielu postaci

### 4.3 Response Format
- [X] ZwykÅ‚y response (nie streaming dla uproszczenia)
- [X] Response: `{ text: string, characterId: string, tokensUsed, model }`
- [X] ObsÅ‚uga bÅ‚Ä™dÃ³w i timeoutÃ³w
- [X] Limity dÅ‚ugoÅ›ci odpowiedzi (aby TTS nie byÅ‚ za dÅ‚ugi)

---

## ğŸ”„ Faza 5: State Management

### 5.1 Stany Aplikacji
- [X] Typ: `AppState = 'waiting' | 'listening' | 'processing' | 'responding'`
- [X] Hook lub store do zarzÄ…dzania stanem (Zustand recommended)
- [X] Synchronizacja stanu z VideoPlayer i Audio

### 5.2 Flow StanÃ³w - GÅOSOWA INTERAKCJA
```
waiting 
  â†“ (user clicks "Speak" button)
listening (nagrywanie audio uÅ¼ytkownika)
  â†“ (user stops lub auto-stop po ciszy)
processing (STT â†’ LLM â†’ TTS generation)
  â†“ (audio ready)
responding (odtwarzanie audio + animacja)
  â†“ (audio koÅ„czy siÄ™)
waiting
```

Substany podczas `processing`:
- `transcribing` - konwersja mowy na tekst
- `thinking` - LLM generuje odpowiedÅº
- `synthesizing` - generowanie audio z ElevenLabs

- [X] Implementacja maszyny stanÃ³w
- [X] Event handlers dla przejÅ›Ä‡
- [X] ObsÅ‚uga przerwania (user moÅ¼e przerwaÄ‡ `responding`)

### 5.3 Historia Konwersacji
- [X] Typ wiadomoÅ›ci:
  ```typescript
  interface Message {
    id: string;
    role: 'user' | 'assistant';
    content: string;           // Tekst (transkrypcja lub odpowiedÅº)
    audioUrl?: string;         // Opcjonalne audio (dla asystenta)
    timestamp: number;
  }
  ```
- [X] Przechowywanie historii w state
- [X] WysyÅ‚anie kontekstu do LLM (ostatnie N wiadomoÅ›ci)
- [X] Opcjonalne: WyÅ›wietlanie transkrypcji (aby user wiedziaÅ‚ co zrozumiaÅ‚ system)

---

## ğŸ¬ Faza 6: Integracja Wideo z Audio i LogikÄ…

### 6.1 Event Handlers
- [X] `onRecordingStart` â†’ zmiana wideo na `listening`
- [X] `onRecordingStop` â†’ pozostaje `listening` (lub `processing`)
- [X] `onAudioPlayStart` â†’ zmiana wideo na `responding` (gotowe dla Fazy 7)
- [X] `onAudioPlayEnd` â†’ zmiana wideo na `waiting` (gotowe dla Fazy 7)
- [X] PodÅ‚Ä…czenie zdarzeÅ„ do VideoPlayer

### 6.2 Synchronizacja Audio + Wideo
- [X] Automatyczna zmiana filmu na podstawie stanu aplikacji
- [X] Film `responding.mp4` na loop (jeÅ›li audio dÅ‚uÅ¼sze niÅ¼ film)
- [X] PÅ‚ynne przejÅ›cia miÄ™dzy filmami z transition effects
- [X] Callback `onVideoChange` dla synchronizacji z audio

### 6.3 Optymalizacja
- [X] Enhanced preloading wszystkich filmÃ³w przy starcie z cache
- [X] Bufferowanie dla pÅ‚ynnych przejÅ›Ä‡
- [X] Error handling dla bÅ‚Ä™dÃ³w Å‚adowania filmÃ³w
- [X] User interaction handler dla autoplay
- [X] Debug info overlay (moÅ¼na wyÅ‚Ä…czyÄ‡ w produkcji)

---

## ğŸ™ï¸ Faza 7: Text-to-Speech z ElevenLabs - OBOWIÄ„ZKOWE

### 7.1 Integracja ElevenLabs
**Dlaczego ElevenLabs?**
- âœ… Najlepsza jakoÅ›Ä‡ gÅ‚osu na rynku
- âœ… NaturalnoÅ›Ä‡ i emocje w gÅ‚osie
- âœ… MoÅ¼liwoÅ›Ä‡ klonowania gÅ‚osu (jeÅ›li masz nagrania aktora)
- âœ… Multilingual (polski obsÅ‚ugiwany)
- âœ… Streaming audio (dla niskich latency)

**Alternatywy (gorsza jakoÅ›Ä‡):**
- OpenAI TTS - dobra, ale mniej naturalna
- Google TTS - Å›rednia jakoÅ›Ä‡
- Web Speech API - najgorsza jakoÅ›Ä‡ (nie polecane)

### 7.2 Setup ElevenLabs
- [X] Rejestracja na elevenlabs.io (user TODO)
- [X] WybÃ³r planu (Free tier: 10k characters/month)
- [X] Pobranie API key (user TODO)
- [X] Dodanie do `.env.local`: `ELEVENLABS_API_KEY`
- [X] WybÃ³r gÅ‚osu lub klonowanie gÅ‚osu aktora
  - [X] PrzeglÄ…danie Voice Library
  - [X] Voice ID: JBFqnCBsd6RMkjVDRZzb (George - British male)
  - [X] Zapisanie `voiceId` do konfiguracji postaci w `lib/characters.ts`

### 7.3 API Implementation
- [X] Utworzenie `/api/text-to-speech` endpoint
- [X] Instalacja: `npm install @elevenlabs/elevenlabs-js`
- [X] Implementacja:
  ```typescript
  import { ElevenLabsClient } from "@elevenlabs/elevenlabs-js";
  
  // Convert text to audio
  // Return audio stream or buffer
  ```
- [X] Parametry:
  - [X] `voiceId` - ID gÅ‚osu postaci
  - [X] `text` - tekst do powiedzenia
  - [X] `modelId` - `eleven_multilingual_v2` (dla polskiego)
  - [X] `voice_settings` - stability, similarity_boost, style, use_speaker_boost

### 7.4 Audio Playback
- [X] Hook `useAudioPlayback` (zamiast komponentu)
- [X] Odtwarzanie audio z API response (Blob/ArrayBuffer)
- [X] Format: MP3 (mp3_44100_128)
- [X] Event listeners:
  - [X] `onPlayStart` â†’ trigger `responding` state
  - [X] `onPlayEnd` â†’ trigger `waiting` state
  - [X] `onError` â†’ error handling
- [X] Button "Stop" aby przerwaÄ‡ audio (interrupt handler)
- [X] Progress tracking (currentTime, duration)

### 7.5 Synchronizacja Video + Audio
- [X] Start audio = automatyczna zmiana na `responding` state
- [X] Video player automatycznie przeÅ‚Ä…cza na `responding.mp4`
- [X] Loop filmu jeÅ›li audio dÅ‚uÅ¼sze (juÅ¼ zaimplementowane w VideoPlayer)
- [X] Jednoczesne zakoÅ„czenie audio i powrÃ³t do `waiting.mp4`

### 7.6 Rekomendowane Ustawienia ElevenLabs
```typescript
// Dla naturalnej konwersacji (ZAIMPLEMENTOWANE)
{
  voice_id: "voiceId_z_characters",
  model_id: "eleven_multilingual_v2",  // Dla polskiego
  voice_settings: {
    stability: 0.5,           // 0-1: niÅ¼sze = bardziej ekspresywne
    similarity_boost: 0.75,   // 0-1: dopasowanie do oryginalnego gÅ‚osu
    style: 0.0,              // 0-1: styl/emocje (opcjonalne)
    use_speaker_boost: true   // Lepsza jakoÅ›Ä‡
  },
  optimize_streaming_latency: 3,  // 0-4: 3 = dobry balans
  output_format: "mp3_44100_128"  // Good quality, reasonable size
}
```

---

## ğŸ” Faza 8: BezpieczeÅ„stwo i Konfiguracja

### 8.1 Environment Variables
- [ ] `.env.local`:
  ```
  # OpenAI (uÅ¼ywane dla Whisper STT + opcjonalnie GPT LLM)
  OPENAI_API_KEY=sk-...
  
  # LLM Provider (wybierz jeden - jeÅ›li nie uÅ¼ywasz GPT)
  # ANTHROPIC_API_KEY=sk-ant-...   # JeÅ›li uÅ¼ywasz Claude
  # GROQ_API_KEY=...               # JeÅ›li uÅ¼ywasz Groq
  
  # Text-to-Speech (obowiÄ…zkowe)
  ELEVENLABS_API_KEY=...
  
  # App Config
  NEXT_PUBLIC_APP_URL=http://localhost:3000
  NODE_ENV=development
  ```
- [ ] Walidacja kluczy API przy starcie
- [ ] Rate limiting (opcjonalne ale zalecane)
- [ ] Dodanie `.env.example` do repo (bez prawdziwych kluczy)

### 8.2 Ochrona API
- [ ] Weryfikacja origin requestÃ³w
- [ ] Rate limiting na endpointy
- [ ] Sanityzacja inputÃ³w uÅ¼ytkownika

---

## ğŸ¯ Faza 9: FunkcjonalnoÅ›ci Dodatkowe

### 9.1 Multi-Character Support (opcjonalne)
- [ ] WybÃ³r postaci przed rozpoczÄ™ciem rozmowy
- [ ] RÃ³Å¼ne system prompty dla rÃ³Å¼nych postaci
- [ ] RÃ³Å¼ne gÅ‚osy ElevenLabs dla kaÅ¼dej postaci
- [ ] RÃ³Å¼ne zestawy animacji (3 filmy Ã— N postaci)
- [ ] Menu wyboru postaci

### 9.2 Historia RozmÃ³w
- [ ] LocalStorage dla historii konwersacji
- [ ] WyÅ›wietlanie transkrypcji (co user powiedziaÅ‚, co postaÄ‡ odpowiedziaÅ‚a)
- [ ] Button "Nowa rozmowa" (reset historii)
- [ ] Export transkrypcji do TXT
- [ ] Opcjonalnie: zapis nagraÅ„ audio

### 9.3 Ustawienia
- [ ] Regulacja gÅ‚oÅ›noÅ›ci audio odpowiedzi
- [ ] WybÃ³r trybu STT:
  - [ ] Web Speech API (darmowy)
  - [ ] Whisper (pÅ‚atny, lepsza jakoÅ›Ä‡)
- [ ] Toggle transkrypcji na ekranie
- [ ] Ustawienia jÄ™zyka interfejsu
- [ ] Debug mode (pokazuje substany: transcribing, thinking, etc.)

---

## ğŸ§ª Faza 10: Testowanie

### 10.1 Testy Funkcjonalne
- [ ] Test przejÅ›Ä‡ miÄ™dzy stanami (waitingâ†’listeningâ†’processingâ†’respondingâ†’waiting)
- [ ] Test nagrywania audio (mikrofon dziaÅ‚a)
- [ ] Test STT (rozpoznaje mowÄ™ po polsku)
- [ ] Test integracji z LLM (odpowiada sensownie)
- [ ] Test TTS z ElevenLabs (audio gra poprawnie)
- [ ] Test synchronizacji wideo + audio

### 10.2 Testy Audio
- [ ] Test z rÃ³Å¼nymi mikrofonami
- [ ] Test poziomu gÅ‚oÅ›noÅ›ci (za gÅ‚oÅ›no/cicho)
- [ ] Test z szumem w tle
- [ ] Test przerwania audio w trakcie
- [ ] Test kolejkowania (czy dziaÅ‚a po sobie)

### 10.3 Testy UX
- [ ] Test na rÃ³Å¼nych przeglÄ…darkach:
  - [ ] Chrome (gÅ‚Ã³wny target)
  - [ ] Safari (Web Speech API ma ograniczenia)
  - [ ] Firefox
  - [ ] Mobile browsers
- [ ] Test responsywnoÅ›ci (mobile + desktop)
- [ ] Test wydajnoÅ›ci (loading filmÃ³w, latency)
- [ ] Test z wolnym internetem (czy nie timeout)

### 10.4 Testy Edge Cases
- [ ] Co jeÅ›li user nie da permisji do mikrofonu?
- [ ] Co jeÅ›li API zwrÃ³ci bÅ‚Ä…d?
- [ ] Co jeÅ›li user mÃ³wi za dÅ‚ugo?
- [ ] Co jeÅ›li user klika wielokrotnie "Speak"?
- [ ] Co jeÅ›li API timeout (LLM lub ElevenLabs)?

---

## ğŸš€ Faza 11: Deployment

### 11.1 Przygotowanie
- [ ] Optymalizacja buildÃ³w
- [ ] Kompresja assetÃ³w (wideo)
- [ ] Setup CDN dla filmÃ³w (opcjonalne)

### 11.2 Deploy
- [ ] WybÃ³r platformy:
  - [ ] Vercel (rekomendowane dla Next.js)
  - [ ] Netlify
  - [ ] Custom VPS
- [ ] Konfiguracja environment variables
- [ ] Konfiguracja domeny (opcjonalne)

### 11.3 Monitoring
- [ ] Setup analytics (opcjonalne)
- [ ] Error tracking (Sentry)
- [ ] Performance monitoring

---

## ğŸ“ Faza 12: Dokumentacja

### 12.1 Dokumentacja Techniczna
- [ ] README.md z instrukcjÄ… uruchomienia
- [ ] Dokumentacja API endpoints
- [ ] Opis architektury

### 12.2 Instrukcje dla UÅ¼ytkownika
- [ ] Jak dodaÄ‡ nowe prompty postaci
- [ ] Jak wymieniÄ‡ filmy animacji
- [ ] Troubleshooting

---

## ğŸ­ Faza 13: Personalizacja Postaci i GÅ‚osu

### 13.1 System PromptÃ³w
- [ ] Utworzenie pliku `/lib/characters.ts`
- [ ] Interface:
  ```typescript
  interface Character {
    id: string;
    name: string;
    description: string;
    systemPrompt: string;      // Instrukcje jak ma rozmawiaÄ‡
    voiceId: string;            // ID gÅ‚osu z ElevenLabs
    videoSet: {
      waiting: string;
      listening: string;
      responding: string;
    };
    llmConfig: {
      temperature: number;      // 0.7-1.0 dla kreatywnoÅ›ci
      maxTokens: number;        // Max dÅ‚ugoÅ›Ä‡ odpowiedzi
      model: string;            // gpt-4, claude-3-opus, etc.
    };
  }
  ```
- [ ] Import instrukcji postaci (gdy bÄ™dÄ… gotowe od Ciebie)
- [ ] MoÅ¼liwoÅ›Ä‡ wielu postaci

### 13.2 WybÃ³r GÅ‚osu ElevenLabs
- [ ] Opcja A: WybÃ³r z Voice Library ElevenLabs
  - [ ] PrzeglÄ…dnij https://elevenlabs.io/voice-library
  - [ ] Wybierz gÅ‚os pasujÄ…cy do postaci
  - [ ] Skopiuj Voice ID
- [ ] Opcja B: Voice Cloning (jeÅ›li masz nagrania aktora)
  - [ ] Nagraj 3-5 minut mowy aktora (czysty audio)
  - [ ] Upload do ElevenLabs â†’ Instant Voice Cloning
  - [ ] Otrzymasz Voice ID

### 13.3 Dostrojenie Zachowania
- [ ] Testy rÃ³Å¼nych `temperature` dla LLM (0.7-1.0)
- [ ] Dostrojenie dÅ‚ugoÅ›ci odpowiedzi (krÃ³tsze = lepsze dla dialogu)
- [ ] Testy ElevenLabs `voice_settings`:
  - [ ] `stability` (0.0-1.0) - 0.5 default
  - [ ] `similarity_boost` (0.0-1.0) - 0.75 default
  - [ ] `style` (opcjonalnie dla emocji)
- [ ] A/B testy rÃ³Å¼nych promptÃ³w
- [ ] Iteracja na podstawie feedbacku uÅ¼ytkownikÃ³w

---

## âš¡ Faza 14: Optymalizacja Latency (WaÅ¼ne!)

### 14.1 Problem Latency w Voice Apps
```
User mÃ³wi (3s) 
  â†’ STT (0.5-2s) 
  â†’ LLM (1-5s) 
  â†’ TTS (1-3s) 
  â†’ Total: 5-13s opÃ³Åºnienia!
```

### 14.2 Optymalizacje STT (Whisper)
- [ ] **Whisper latency:** ~0.5-2s w zaleÅ¼noÅ›ci od dÅ‚ugoÅ›ci audio
- [ ] Optymalizacje:
  - [ ] WysyÅ‚aj audio zaraz po zakoÅ„czeniu nagrania
  - [ ] UÅ¼ywaj kompresji audio (webm/opus - mniejsze pliki)
  - [ ] Auto-detect koÅ„ca wypowiedzi (silence detection)
  - [ ] Nie czekaj aÅ¼ user kliknie "stop" - auto-stop po 1-2s ciszy
- [ ] Alternatywa: Web Speech API jako fallback (0 latency ale gorsza jakoÅ›Ä‡)

### 14.3 Optymalizacje LLM
- [ ] UÅ¼yj szybszego modelu:
  - GPT-3.5-turbo zamiast GPT-4 (4x szybszy)
  - Groq (ultra szybki inference)
  - Claude 3 Haiku (szybki, taÅ„szy)
- [ ] Ogranicz `max_tokens` (krÃ³tsze odpowiedzi = szybsze)
- [ ] Streaming response (opcjonalnie)

### 14.4 Optymalizacje TTS
- [ ] **ElevenLabs Streaming** (najwaÅ¼niejsze!)
  - [ ] UÅ¼yj `/v1/text-to-speech/{voice_id}/stream`
  - [ ] Audio zaczyna graÄ‡ natychmiast (chunk by chunk)
  - [ ] Redukuje latency z 3s â†’ 0.5s
- [ ] UÅ¼yj `optimize_streaming_latency` parameter
- [ ] Cache popularnych fraz (opcjonalnie)

### 14.5 UX dla Latency
- [ ] Loading indicators z procentami
- [ ] "MyÅ›lÄ™..." message podczas LLM processing
- [ ] Animacja "thinking" w czasie przetwarzania
- [ ] Preload pierwszej czÄ™Å›ci audio (streaming)
- [ ] Feedback: "Przetwarzam..." â†’ "Za chwilÄ™ odpowiem..."

### 14.6 Target Latency (cel)
- âœ… Ideal: <3s od koÅ„ca mowy do poczÄ…tku odpowiedzi
- âš ï¸ Acceptable: 3-5s
- âŒ Too slow: >5s

---

## ğŸ“Š Priorytety

### Must Have (MVP) - GÅ‚osowa Interakcja
1. âœ… Setup Next.js z TypeScript (DONE - Faza 1)
2. âœ… Video player z trzema stanami (DONE - Faza 2)
3. âœ… State management (Zustand) (DONE - Faza 2 & 5)
4. âœ… Voice controls UI (DONE - Faza 2)
5. âœ… **Speech-to-Text** (Whisper) (DONE - Faza 3)
6. âœ… **Integracja z LLM GPT-5.2** (DONE - Faza 4)
7. âœ… **Synchronizacja wideo z logikÄ…** (DONE - Faza 6)
8. âœ… **Text-to-Speech z ElevenLabs** (DONE - Faza 7) ğŸ‰

## ğŸ‰ MVP COMPLETE! PeÅ‚ny workflow gotowy:
User mÃ³wi â†’ Whisper STT â†’ GPT-5.2 LLM â†’ ElevenLabs TTS â†’ Audio + Video playback

### Nice to Have (V2)
- Multi-character support (kilka postaci)
- Historia rozmÃ³w z transkrypcjÄ…
- Audio visualizer
- WybÃ³r metody STT w ustawieniach
- Export transkrypcji

### Future Enhancements (V3)
- Voice cloning dla konkretnego aktora
- Emotions detection (zmiana tonu gÅ‚osu)
- Admin panel do zarzÄ…dzania postaciami
- Analytics rozmÃ³w
- Mobile app (React Native)
- Tryb offline (edge cases)

---

## ğŸ› ï¸ Stack Technologiczny

**Frontend:**
- Next.js 14+ (App Router)
- TypeScript
- Tailwind CSS
- Shadcn/ui (komponenty)
- Zustand (state management)

**Backend (Next.js API Routes):**
- `/api/speech-to-text` - **OpenAI Whisper** (gÅ‚Ã³wny STT)
- `/api/llm-chat` - OpenAI GPT / Anthropic Claude / Groq
- `/api/text-to-speech` - **ElevenLabs API** (gÅ‚Ã³wny TTS)

**Audio/Video:**
- MediaRecorder API (nagrywanie)
- HTML5 Video (animacje)
- HTML5 Audio (odtwarzanie TTS)
- Web Speech API (opcjonalne STT)

**External APIs:**
- **ElevenLabs** - Text-to-Speech (OBOWIÄ„ZKOWE) âœ…
- **OpenAI Whisper** - Speech-to-Text (WYBRANE) âœ…
- **OpenAI GPT / Anthropic Claude / Groq** - LLM (do wyboru)

**Deployment:**
- Vercel (recommended) - zero-config dla Next.js
- Cloudflare R2 / AWS S3 - hosting filmÃ³w (opcjonalnie)

**Development:**
- pnpm / npm - package manager
- ESLint + Prettier
- Git

---

## ğŸ“Œ Notatki i Decyzje

### Do UzupeÅ‚nienia:
- [ ] **System prompt postaci** - dostosowaÄ‡ w `lib/characters.ts` (Faza 4.2)
- [X] **WybÃ³r providera LLM:**
  - âœ… OpenAI GPT-5.2 (NAJNOWSZY - 11.12.2025) - UÅ»YWANY
  - OpenAI GPT-4o / GPT-4-turbo (alternatywy)
  - Anthropic Claude (dostÄ™pne w konfiguracji)
  - Groq (dostÄ™pne w konfiguracji)
- [ ] **PrzygotowaÄ‡ 3 filmy animacji:**
  - `waiting.mp4` - postaÄ‡ czeka na interakcjÄ™ (loop)
  - `listening.mp4` - postaÄ‡ sÅ‚ucha uÅ¼ytkownika (loop)
  - `responding.mp4` - postaÄ‡ mÃ³wi/odpowiada (loop)
  - Zalecane: <10MB kaÅ¼dy, format MP4, H.264
- [ ] **ZarejestrowaÄ‡ konta:**
  - OpenAI account + API key (dla Whisper + opcjonalnie GPT)
  - ElevenLabs account + API key
  - (Opcjonalnie) Anthropic/Groq jeÅ›li wybierzesz inny LLM

### âœ… Potwierdzone Decyzje:
- âœ… **STT: OpenAI Whisper** (lepsza jakoÅ›Ä‡ niÅ¼ Web Speech API)
- âœ… **TTS: ElevenLabs** (najlepsza jakoÅ›Ä‡ gÅ‚osu)
- âœ… **Tryb: Tylko gÅ‚osowa interakcja** (brak chatu tekstowego)
- âœ… **Framework: Next.js** z TypeScript

### Koszty (szacowane):
- **ElevenLabs:**
  - Free Tier: 10,000 znakÃ³w/miesiÄ…c (darmowe, ~10-15 min mowy)
  - Creator: $11/mo - 100,000 znakÃ³w (~1.5h mowy)
- **OpenAI Whisper:** ~$0.006/minuta
  - PrzykÅ‚ad: 100 rozmÃ³w Ã— 2 min = $1.20/miesiÄ…c
- **LLM:**
  - GPT-3.5-turbo: ~$0.002/1000 tokenÃ³w (bardzo tanie)
  - GPT-4: ~$0.03/1000 tokenÃ³w (droÅ¼sze, ale lepsze)
  - Claude/Groq: podobnie
- **Deployment (Vercel):** Darmowy dla hobby projectÃ³w
- **TOTAL dla MVP:** ~$15-30/miesiÄ…c (z umiarkowanym uÅ¼yciem)

---

## ğŸš€ Quick Start Guide (gdy zaczniesz implementacjÄ™)

### Krok 1: Setup
```bash
npx create-next-app@latest tech-theater --typescript --tailwind --app
cd tech-theater
npm install elevenlabs openai zustand @radix-ui/react-icons
```

### Krok 2: Struktura
```
/app
  /api
    /speech-to-text/route.ts
    /llm-chat/route.ts
    /text-to-speech/route.ts
  /components
    /VideoPlayer.tsx
    /VoiceControls.tsx
  /lib
    /characters.ts
    /elevenlabs.ts
  page.tsx
```

### Krok 3: Env Variables
```bash
# .env.local
OPENAI_API_KEY=your_key_here      # Dla Whisper STT (+ opcjonalnie GPT)
ELEVENLABS_API_KEY=your_key_here  # Dla TTS
# ANTHROPIC_API_KEY=...           # JeÅ›li uÅ¼ywasz Claude zamiast GPT
```

### Krok 4: Dodaj Filmy
```
/public/videos/
  waiting.mp4
  listening.mp4
  responding.mp4
```

### Krok 5: Zaimplementuj w kolejnoÅ›ci:
1. VideoPlayer (najprostsze)
2. State management (Zustand)
3. Voice recording (MediaRecorder + auto-stop)
4. API routes:
   - `/api/speech-to-text` (Whisper)
   - `/api/llm-chat` (GPT/Claude/Groq)
   - `/api/text-to-speech` (ElevenLabs)
5. Integration & synchronizacja wszystkich komponentÃ³w

### Krok 6: Testowanie
- Test nagrywania â†’ sprawdÅº czy audio siÄ™ nagrywa
- Test Whisper â†’ sprawdÅº czy rozpoznaje polski
- Test LLM â†’ sprawdÅº czy odpowiada sensownie
- Test ElevenLabs â†’ sprawdÅº czy mÃ³wi naturalnie
- Test synchronizacji â†’ sprawdÅº czy video zmienia siÄ™ z audio

---

---

## â“ FAQ - NajczÄ™stsze Pytania

### Q: Czy mogÄ™ uÅ¼ywaÄ‡ innego TTS niÅ¼ ElevenLabs?
**A:** Tak, ale ElevenLabs ma najlepszÄ… jakoÅ›Ä‡. Alternatywy:
- OpenAI TTS (dobra jakoÅ›Ä‡, ale mniej naturalna)
- Google Cloud TTS (Å›rednia)
- Web Speech API (najgorsza - nie polecane)

### Q: Ile kosztuje ElevenLabs?
**A:** 
- Free tier: 10,000 znakÃ³w/miesiÄ…c (~10-15 minut mowy)
- Creator: $11/mo - 100,000 znakÃ³w (~1.5h mowy)
- Pro: $99/mo - 500,000 znakÃ³w (~8h mowy)

### Q: Czy potrzebujÄ™ pÅ‚atnego konta OpenAI?
**A:** 
- **Dla Whisper (STT): TAK** - wybrana opcja, bardzo tanie (~$0.006/minuta)
- Dla GPT (LLM): Opcjonalnie - moÅ¼esz uÅ¼yÄ‡ Claude lub Groq zamiast GPT
- Koszt Whisper: ~$1-2/miesiÄ…c dla umiarkowanego uÅ¼ycia
- Alternatywa dla LLM: Claude (Anthropic) lub Groq

### Q: Czy dziaÅ‚a na telefonach?
**A:** 
- âœ… **TAK** - Whisper dziaÅ‚a na wszystkich przeglÄ…darkach!
- iOS Safari: âœ… PeÅ‚ne wsparcie (MediaRecorder)
- Android Chrome: âœ… PeÅ‚ne wsparcie
- Wymaga tylko permisji do mikrofonu
- Whisper nie wymaga specyficznej przeglÄ…darki (w przeciwieÅ„stwie do Web Speech API)

### Q: Jak przyspieszyÄ‡ odpowiedzi?
**A:**
1. **UÅ¼yj ElevenLabs streaming** (najwaÅ¼niejsze! redukuje latency z 3s â†’ 0.5s)
2. UÅ¼yj szybszego LLM (GPT-3.5 zamiast GPT-4, lub Groq)
3. Ogranicz dÅ‚ugoÅ›Ä‡ odpowiedzi (`max_tokens` ~150-300)
4. Auto-stop nagrywania po ciszy (nie czekaj na manual stop)
5. Kompresuj audio przed wysÅ‚aniem do Whisper (webm/opus)

### Q: Czy mogÄ™ mieÄ‡ wiele postaci?
**A:** Tak! KaÅ¼da postaÄ‡ ma:
- WÅ‚asny system prompt
- WÅ‚asny gÅ‚os ElevenLabs (voice_id)
- WÅ‚asny zestaw 3 filmÃ³w animacji
- Selector w UI do wyboru postaci

### Q: Co jeÅ›li user nie da permisji do mikrofonu?
**A:** 
- ObsÅ‚uÅ¼ error gracefully
- PokaÅ¼ instrukcjÄ™ jak wÅ‚Ä…czyÄ‡ mikrofon
- Fallback: brak - aplikacja wymaga mikrofonu

### Q: Dlaczego Whisper zamiast Web Speech API?
**A:**
- âœ… Lepsza jakoÅ›Ä‡ rozpoznawania (~95% vs ~70-80%)
- âœ… DziaÅ‚a na wszystkich przeglÄ…darkach (iOS Safari, Firefox, etc.)
- âœ… Lepsze rozpoznawanie polskiego jÄ™zyka
- âœ… Nie wymaga specyficznej przeglÄ…darki
- âš ï¸ Wady: PÅ‚atne (~$0.006/min), minimalne opÃ³Åºnienie (~0.5-2s)
- ğŸ’¡ Web Speech API moÅ¼na dodaÄ‡ jako fallback

### Q: Jakie sÄ… limity Whisper?
**A:**
- Max wielkoÅ›Ä‡ pliku: 25MB
- Max dÅ‚ugoÅ›Ä‡ audio: brak oficjalnego limitu, ale rekomendowane <10 min
- Formaty: mp3, mp4, mpeg, mpga, m4a, wav, webm
- Koszt: $0.006 za minutÄ™ audio (bardzo tanie!)
- Rate limits: 50 requests/min (wiÄ™cej niÅ¼ potrzeba)

### Q: Jak dÅ‚ugie mogÄ… byÄ‡ filmy?
**A:**
- Rekomendacja: 3-10 sekund kaÅ¼dy
- Format: MP4, H.264, <10MB
- Filmy bÄ™dÄ… loopowane, wiÄ™c mogÄ… byÄ‡ krÃ³tkie
- `responding.mp4` powinien byÄ‡ najdÅ‚uÅ¼szy

### Q: Czy mogÄ™ uÅ¼yÄ‡ gÅ‚osu mojego aktora?
**A:** Tak! ElevenLabs Voice Cloning:
- Potrzebujesz 3-5 minut czystego audio aktora
- Upload do ElevenLabs â†’ Instant Voice Cloning
- Otrzymasz unique voice_id
- Plan Professional+ wymagany ($99/mo)

---

**Status:** â³ Projekt w planowaniu
**Data utworzenia:** 12.12.2025
**Wersja planu:** 2.0 (Voice-Only)
**Ostatnia aktualizacja:** 12.12.2025

